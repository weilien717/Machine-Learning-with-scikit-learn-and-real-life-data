{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc38cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, RationalQuadratic, ExpSineSquared, ConstantKernel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn.metrics\n",
    "encoder = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2b7a5558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using the Randomized Search\n",
    "def trainModel(model, param_distributions, X_trn, y_trn, data_name, **kwargs):\n",
    "    clf = model(**kwargs)\n",
    "    print('Trainning', clf.__class__.__name__ ,' model with ' , data_name , 'data...')\n",
    "    \n",
    "    #use standard scaler to scale the data\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    X_trn = scaler.fit_transform(X_trn)\n",
    "    \n",
    "    search = sklearn.model_selection.RandomizedSearchCV(clf, param_distributions)\n",
    "    search.fit(X_trn, y_trn)\n",
    "    best_param = search.best_params_\n",
    "    print('using' , search.best_estimator_)\n",
    "    clf = model(**kwargs)\n",
    "    clf.set_params(**best_param)\n",
    "    clf.fit(X_trn, y_trn)\n",
    "    return clf\n",
    "\n",
    "# train the model using the Grid Search\n",
    "def trainModelGridSearch(model, param_distributions, X_trn, y_trn, data_name, **kwargs):\n",
    "    clf = model(**kwargs)\n",
    "    print('Trainning', clf.__class__.__name__ ,' model with ' , data_name , 'data...')\n",
    "    \n",
    "    #use standard scaler to scale the data\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    X_trn = scaler.fit_transform(X_trn)\n",
    "    \n",
    "    search = sklearn.model_selection.GridSearchCV(clf, param_distributions)\n",
    "    search.fit(X_trn, y_trn)\n",
    "    best_param = search.best_params_\n",
    "    print('using' , search.best_estimator_)\n",
    "    clf = model(**kwargs)\n",
    "    clf.set_params(**best_param)\n",
    "    clf.fit(X_trn, y_trn)\n",
    "    return clf\n",
    "\n",
    "# compute the score of the input estimator\n",
    "def computeScore(estimator, X_test, y_test, data_name):\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    score = np.mean((y_test-y_pred)**2)*100\n",
    "    #score = round(estimator.score(X_test, y_test), 2 )* 100\n",
    "    print('testing accuracy using ', estimator.__class__.__name__, 'for data', data_name , score, '%')\n",
    "    print()\n",
    "    return score\n",
    "\n",
    "def separateData(X,y):\n",
    "    X_trn, X_tst, y_trn, y_tst = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    return X_trn, X_tst, y_trn, y_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eb3ae58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all the classifiers with different \n",
    "def train_with_all_classifier(X_trn, y_trn, data_name, X_tst, y_tst):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    estimators = []\n",
    "    scores = []\n",
    "    \n",
    "    #Linear Regression\n",
    "    logistic_estimator = sklearn.linear_model.LinearRegression()\n",
    "    print('Training Linear regression model with ' , data_name , 'dataset')\n",
    "    logistic_estimator.fit(X_trn,y_trn)\n",
    "    estimators.append(logistic_estimator)\n",
    "    scores.append(computeScore(logistic_estimator, X_tst, y_tst, data_name))\n",
    "    \n",
    "    #SVM\n",
    "    param_distributions = {\n",
    "        'C' : [0.01,0.1,1.0],\n",
    "        'gamma' : [0.1,0.5,2.0]\n",
    "    }\n",
    "    \n",
    "    svr_estimator = trainModelGridSearch(sklearn.svm.SVR, param_distributions, X_trn, \n",
    "                                         y_trn, data_name, max_iter = 1)\n",
    "    estimators.append(svr_estimator)\n",
    "    scores.append(computeScore(svr_estimator, X_tst, y_tst, data_name))\n",
    "\n",
    "    \n",
    "    #Decision Tree Classifier\n",
    "    param_distributions = {\n",
    "            'criterion' : ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "            'max_depth' : [2,4,6]\n",
    "    }\n",
    "    decision_tree_estimator = trainModel(sklearn.tree.DecisionTreeRegressor, param_distributions, X_trn, \n",
    "                                         y_trn, data_name)\n",
    "    estimators.append(decision_tree_estimator)\n",
    "    scores.append(computeScore(decision_tree_estimator, X_tst, y_tst, data_name))\n",
    "    \n",
    "    #Random Forest Classifier\n",
    "    param_distributions = {\n",
    "            'n_estimators' : [50,100,200],\n",
    "            'max_depth' : [1,2,4]\n",
    "    }\n",
    "    randomForest_estimator = trainModel(sklearn.ensemble.RandomForestRegressor, param_distributions, X_trn, \n",
    "                                         y_trn, data_name)\n",
    "    estimators.append(randomForest_estimator)\n",
    "    scores.append(computeScore(randomForest_estimator, X_tst, y_tst, data_name))\n",
    "    \n",
    "    #KNeighborsRegressor\n",
    "    param_distributions = {\n",
    "            'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            'n_neighbors' : [5,10,20]\n",
    "    }\n",
    "    kneighbours_estimator = trainModel(sklearn.neighbors.KNeighborsRegressor, param_distributions, X_trn, \n",
    "                                         y_trn, data_name)\n",
    "    estimators.append(kneighbours_estimator)\n",
    "    scores.append(computeScore(kneighbours_estimator, X_tst, y_tst, data_name))\n",
    "    \n",
    "    #Adaboost\n",
    "    param_distributions = {\n",
    "            'n_estimators' : [10, 30, 50,100],\n",
    "            'learning_rate' : [0.2,1.0,1.2,2.0]\n",
    "    }\n",
    "    Adaboost_estimator = trainModel(sklearn.ensemble.AdaBoostRegressor, param_distributions, X_trn, \n",
    "                                         y_trn, data_name, random_state=0)\n",
    "    estimators.append(Adaboost_estimator)\n",
    "    scores.append(computeScore(Adaboost_estimator, X_tst, y_tst, data_name))\n",
    "    \n",
    "    \n",
    "    #GaussianProcessRegressor\n",
    "    param_distributions = {\n",
    "            'alpha' : [0.00000001,0.001,1,10,100],\n",
    "            'n_restarts_optimizer' : [0,1,2,3]\n",
    "    }\n",
    "    Gaussian_estimator = trainModel(sklearn.gaussian_process.GaussianProcessRegressor, param_distributions, X_trn, \n",
    "                                         y_trn, data_name, random_state=0)\n",
    "    estimators.append(Gaussian_estimator)\n",
    "    scores.append(computeScore(Gaussian_estimator, X_tst, y_tst, data_name))\n",
    "\n",
    "    \n",
    "    #neural_network MLPRegressor\n",
    "    param_distributions = {\n",
    "            'hidden_layer_sizes' : [5,10,50,60],\n",
    "            'learning_rate' : ['constant', 'invscaling', 'adaptive']\n",
    "    }\n",
    "    Neural_estimator = trainModel(sklearn.neural_network.MLPRegressor, param_distributions, X_trn, \n",
    "                                         y_trn, data_name, max_iter = 1, random_state=0)\n",
    "    estimators.append(Neural_estimator)\n",
    "    scores.append(computeScore(Neural_estimator, X_tst, y_tst, data_name))\n",
    "    print('---------------------------------------------------')\n",
    "    return estimators, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8f4d0365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBarGraph(score_list, title):\n",
    "    classifier_list = ['Linear Regression', 'SVR', 'DecisionTreeRegressor','RandomForestRegressor','KNeighborsRegressor',\n",
    "                   'AdaBoostRegressor', 'GaussianProcessRegressor','MLPRegressor']\n",
    "    # x-coordinates of left sides of bars\n",
    "    left = []\n",
    "    scores = []\n",
    "    # labels for bars\n",
    "    #tick_label = classifier_list\n",
    "    tick_label = []\n",
    "    plt.figure(figsize=(18,5))\n",
    "    plt.grid(zorder=0)\n",
    "    \n",
    "    plt.title(title)\n",
    "    for i in range(len(score_list)):\n",
    "        if score_list[i] < -10 or score_list[i] > 100:\n",
    "            scores.append(0)\n",
    "        else:\n",
    "            scores.append(score_list[i])\n",
    "        left.append(i+1)\n",
    "        tick_label.append(classifier_list[i])\n",
    "            \n",
    "    plt.bar(left, scores, tick_label = tick_label,\n",
    "            width = 0.2, color = ['red', 'green'])\n",
    "   # print(scores)\n",
    "    best_score = max(scores)\n",
    "    plt.text(6, 60, 'best accuracy estimator = ' + classifier_list[score_list.index(best_score)] + ' score: '+ str(best_score) + ' %' , fontsize=15, color = 'brown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd80e2",
   "metadata": {},
   "source": [
    "# =====================Dataset 1. Wines==========================\n",
    "Since we have white and red wine, let us initialize a new row: color in which it is equal to 1 when the wine is a white wine, 0 if it is red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33277e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0             0.270         0.36            20.7      0.045   \n",
       "1               6.3             0.300         0.34             1.6      0.049   \n",
       "2               8.1             0.280         0.40             6.9      0.050   \n",
       "3               7.2             0.230         0.32             8.5      0.058   \n",
       "4               7.2             0.230         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  color  \n",
       "0         8.8        6      0  \n",
       "1         9.5        6      0  \n",
       "2        10.1        6      0  \n",
       "3         9.9        6      0  \n",
       "4         9.9        6      0  \n",
       "...       ...      ...    ...  \n",
       "1594     10.5        5      1  \n",
       "1595     11.2        6      1  \n",
       "1596     11.0        6      1  \n",
       "1597     10.2        5      1  \n",
       "1598     11.0        6      1  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting the data\n",
    "\n",
    "whiteWine = pd.read_csv('resources2/winequality-white.csv',sep=';')\n",
    "redWine = pd.read_csv('resources2/winequality-red.csv',sep=';')\n",
    "color =[]\n",
    "# 0 is for white color and 1 is for red color\n",
    "for i in range(len(whiteWine)):\n",
    "    color.append(0)\n",
    "for j in range(len(redWine)):\n",
    "    color.append(1)\n",
    "\n",
    "\n",
    "bothWines = pd.concat([whiteWine, redWine], axis=0)\n",
    "bothWines['color'] = color\n",
    "\n",
    "X = bothWines.drop('quality', axis='columns')\n",
    "y = bothWines['quality']\n",
    "\n",
    "\n",
    "X_trn_wine,X_tst_wine,y_trn_wine,y_tst_wine = train_test_split(X,y,random_state=0)\n",
    "\n",
    "display(bothWines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "05146393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear regression model with  Wine dataset\n",
      "testing accuracy using  LinearRegression for data Wine 1896690.3713077598 %\n",
      "\n",
      "Trainning SVR  model with  Wine data...\n",
      "using SVR(gamma=0.1, max_iter=1)\n",
      "testing accuracy using  SVR for data Wine 75.24703001479254 %\n",
      "\n",
      "Trainning DecisionTreeRegressor  model with  Wine data...\n",
      "using DecisionTreeRegressor(criterion='friedman_mse', max_depth=4)\n",
      "testing accuracy using  DecisionTreeRegressor for data Wine 55.67745987207604 %\n",
      "\n",
      "Trainning RandomForestRegressor  model with  Wine data...\n",
      "using RandomForestRegressor(max_depth=4, n_estimators=200)\n",
      "testing accuracy using  RandomForestRegressor for data Wine 52.04970480569343 %\n",
      "\n",
      "Trainning KNeighborsRegressor  model with  Wine data...\n",
      "using KNeighborsRegressor(algorithm='ball_tree', n_neighbors=20)\n",
      "testing accuracy using  KNeighborsRegressor for data Wine 48.39876923076923 %\n",
      "\n",
      "Trainning AdaBoostRegressor  model with  Wine data...\n",
      "using AdaBoostRegressor(learning_rate=0.2, n_estimators=100, random_state=0)\n",
      "testing accuracy using  AdaBoostRegressor for data Wine 52.84986415844782 %\n",
      "\n",
      "Trainning GaussianProcessRegressor  model with  Wine data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-f4a5516d7e1d>\u001b[0m in \u001b[0;36mtrain_with_all_classifier\u001b[0;34m(X_trn, y_trn, data_name, X_tst, y_tst)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;34m'n_restarts_optimizer'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     }\n\u001b[0;32m---> 73\u001b[0;31m     Gaussian_estimator = trainModel(sklearn.gaussian_process.GaussianProcessRegressor, param_distributions, X_trn, \n\u001b[0m\u001b[1;32m     74\u001b[0m                                          y_trn, data_name, random_state=0)\n\u001b[1;32m     75\u001b[0m     \u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGaussian_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-e528ac819ea6>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(model, param_distributions, X_trn, y_trn, data_name, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mbest_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'using'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[1;32m   1768\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_marginal_likelihood_value_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlml_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             self.log_marginal_likelihood_value_ = self.log_marginal_likelihood(\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclone_kernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             )\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mlog_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m# Alg. 2.1, page 19, line 2 -> L = cholesky(K + sigma^2 I)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[1;32m    944\u001b[0m             )\n\u001b[1;32m    945\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[1;32m   1537\u001b[0m             \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m             \u001b[0;31m# convert from upper-triangular matrix to square matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1539\u001b[0;31m             \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msquareform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1540\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_diagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36msquareform\u001b[0;34m(X, force, checks)\u001b[0m\n\u001b[1;32m   2352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2353\u001b[0m         \u001b[0;31m# Fill in the values of the distance matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2354\u001b[0;31m         \u001b[0m_distance_wrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_squareform_from_vector_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         \u001b[0;31m# Return the distance matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wine_estimators, wine_scores = train_with_all_classifier(X_trn_wine, y_trn_wine,\n",
    "                                                                 'Wine', X_tst_wine,y_tst_wine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6dcff0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotBarGraph(wine_scores, 'Wine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dff971",
   "metadata": {},
   "source": [
    "# ===============Dataset 2. Communities and Crimes==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e03e1a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before encoding\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>81440</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>95</td>\n",
       "      <td>6096</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>12</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>TempleTerracecity</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>6</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Seasidecity</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.20</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>80070</td>\n",
       "      <td>Waterburytown</td>\n",
       "      <td>10</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>72600</td>\n",
       "      <td>Walthamcity</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>6</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Ontariocity</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1994 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1      2                    3    4     5     6     7     8     9    \\\n",
       "0       8   ?      ?         Lakewoodcity    1  0.19  0.33  0.02  0.90  0.12   \n",
       "1      53   ?      ?          Tukwilacity    1  0.00  0.16  0.12  0.74  0.45   \n",
       "2      24   ?      ?         Aberdeentown    1  0.00  0.42  0.49  0.56  0.17   \n",
       "3      34   5  81440  Willingborotownship    1  0.04  0.77  1.00  0.08  0.12   \n",
       "4      42  95   6096    Bethlehemtownship    1  0.01  0.55  0.02  0.95  0.09   \n",
       "...   ...  ..    ...                  ...  ...   ...   ...   ...   ...   ...   \n",
       "1989   12   ?      ?    TempleTerracecity   10  0.01  0.40  0.10  0.87  0.12   \n",
       "1990    6   ?      ?          Seasidecity   10  0.05  0.96  0.46  0.28  0.83   \n",
       "1991    9   9  80070        Waterburytown   10  0.16  0.37  0.25  0.69  0.04   \n",
       "1992   25  17  72600          Walthamcity   10  0.08  0.51  0.06  0.87  0.22   \n",
       "1993    6   ?      ?          Ontariocity   10  0.20  0.78  0.14  0.46  0.24   \n",
       "\n",
       "      ...   118   119   120   121   122   123  124   125   126   127  \n",
       "0     ...  0.12  0.26  0.20  0.06  0.04   0.9  0.5  0.32  0.14  0.20  \n",
       "1     ...  0.02  0.12  0.45     ?     ?     ?    ?  0.00     ?  0.67  \n",
       "2     ...  0.01  0.21  0.02     ?     ?     ?    ?  0.00     ?  0.43  \n",
       "3     ...  0.02  0.39  0.28     ?     ?     ?    ?  0.00     ?  0.12  \n",
       "4     ...  0.04  0.09  0.02     ?     ?     ?    ?  0.00     ?  0.03  \n",
       "...   ...   ...   ...   ...   ...   ...   ...  ...   ...   ...   ...  \n",
       "1989  ...  0.01  0.28  0.05     ?     ?     ?    ?  0.00     ?  0.09  \n",
       "1990  ...  0.02  0.37  0.20     ?     ?     ?    ?  0.00     ?  0.45  \n",
       "1991  ...  0.08  0.32  0.18  0.08  0.06  0.78    0  0.91  0.28  0.23  \n",
       "1992  ...  0.03  0.38  0.33  0.02  0.02  0.79    0  0.22  0.18  0.19  \n",
       "1993  ...  0.11  0.30  0.05  0.08  0.04  0.73  0.5  1.00  0.13  0.48  \n",
       "\n",
       "[1994 rows x 128 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>108</td>\n",
       "      <td>799</td>\n",
       "      <td>804</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>108</td>\n",
       "      <td>799</td>\n",
       "      <td>1625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>72</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>63</td>\n",
       "      <td>38</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>108</td>\n",
       "      <td>799</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>38</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>56</td>\n",
       "      <td>725</td>\n",
       "      <td>1787</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>28</td>\n",
       "      <td>63</td>\n",
       "      <td>38</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>105</td>\n",
       "      <td>517</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>38</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>9</td>\n",
       "      <td>108</td>\n",
       "      <td>799</td>\n",
       "      <td>1597</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>85</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>38</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>4</td>\n",
       "      <td>108</td>\n",
       "      <td>799</td>\n",
       "      <td>1455</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>88</td>\n",
       "      <td>46</td>\n",
       "      <td>26</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>63</td>\n",
       "      <td>38</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>6</td>\n",
       "      <td>102</td>\n",
       "      <td>709</td>\n",
       "      <td>1707</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>621</td>\n",
       "      <td>1695</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>4</td>\n",
       "      <td>108</td>\n",
       "      <td>799</td>\n",
       "      <td>1165</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1994 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2     3    4    5    6    7    8    9    ...  118  119  120  \\\n",
       "0       5  108  799   804    0   19   28    2   88   12  ...   12   26   20   \n",
       "1      42  108  799  1625    0    0   11   12   72   45  ...    2   12   45   \n",
       "2      18  108  799     1    0    0   37   49   54   17  ...    1   21    2   \n",
       "3      25   56  725  1787    0    4   71   99    6   12  ...    2   39   28   \n",
       "4      33  105  517   141    0    1   50    2   93    9  ...    4    9    2   \n",
       "...   ...  ...  ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1989    9  108  799  1597    9    1   35   10   85   12  ...    1   28    5   \n",
       "1990    4  108  799  1455    9    5   88   46   26   78  ...    2   37   20   \n",
       "1991    6  102  709  1707    9   16   32   25   67    4  ...    8   32   18   \n",
       "1992   19   34  621  1695    9    8   46    6   85   22  ...    3   38   33   \n",
       "1993    4  108  799  1165    9   20   72   14   44   24  ...   11   30    5   \n",
       "\n",
       "      121  122  123  124  125  126  127  \n",
       "0       6    4   62    1   17   14   20  \n",
       "1      63   38   72    3    0   51   67  \n",
       "2      63   38   72    3    0   51   43  \n",
       "3      63   38   72    3    0   51   12  \n",
       "4      63   38   72    3    0   51    3  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "1989   63   38   72    3    0   51    9  \n",
       "1990   63   38   72    3    0   51   45  \n",
       "1991    8    6   50    0   73   28   23  \n",
       "1992    2    2   51    0    7   18   19  \n",
       "1993    8    4   45    1   79   13   48  \n",
       "\n",
       "[1994 rows x 128 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('resources2/communities.data',sep=',',header=None, skipinitialspace=True)\n",
    "# encode by converting to int\n",
    "print('before encoding')\n",
    "display(data)\n",
    "for i in range(0, 128):\n",
    "    data[i] = encoder.fit_transform(data[i])\n",
    "\n",
    "X = data.drop(127, axis='columns')\n",
    "y = data[127]\n",
    "\n",
    "print('after encoding')\n",
    "display(data)\n",
    "X_trn_crime, X_tst_crime, y_trn_crime, y_tst_crime = separateData(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96153f6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear regression model with  Communities and Crimes dataset\n",
      "testing accuracy using  LinearRegression for data Communities and Crimes 318117.0 %\n",
      "\n",
      "Trainning SVR  model with  Communities and Crimes data...\n",
      "using SVR(gamma=0.5, max_iter=1)\n",
      "testing accuracy using  SVR for data Communities and Crimes 118236.99999999999 %\n",
      "\n",
      "Trainning DecisionTreeRegressor  model with  Communities and Crimes data...\n",
      "using DecisionTreeRegressor(criterion='absolute_error', max_depth=4)\n",
      "testing accuracy using  DecisionTreeRegressor for data Communities and Crimes 27689.999999999996 %\n",
      "\n",
      "Trainning RandomForestRegressor  model with  Communities and Crimes data...\n",
      "using RandomForestRegressor(max_depth=4)\n",
      "testing accuracy using  RandomForestRegressor for data Communities and Crimes 21330.0 %\n",
      "\n",
      "Trainning KNeighborsRegressor  model with  Communities and Crimes data...\n",
      "using KNeighborsRegressor(algorithm='kd_tree', n_neighbors=20)\n",
      "testing accuracy using  KNeighborsRegressor for data Communities and Crimes 24231.0 %\n",
      "\n",
      "Trainning AdaBoostRegressor  model with  Communities and Crimes data...\n",
      "using AdaBoostRegressor(n_estimators=10, random_state=0)\n",
      "testing accuracy using  AdaBoostRegressor for data Communities and Crimes 24451.0 %\n",
      "\n",
      "Trainning GaussianProcessRegressor  model with  Communities and Crimes data...\n",
      "using GaussianProcessRegressor(alpha=1e-08, n_restarts_optimizer=1, random_state=0)\n",
      "testing accuracy using  GaussianProcessRegressor for data Communities and Crimes 116199.0 %\n",
      "\n",
      "Trainning MLPRegressor  model with  Communities and Crimes data...\n",
      "using MLPRegressor(hidden_layer_sizes=5, learning_rate='invscaling', max_iter=1,\n",
      "             random_state=0)\n",
      "testing accuracy using  MLPRegressor for data Communities and Crimes 108285.99999999999 %\n",
      "\n",
      "---------------------------------------------------\n",
      "CPU times: user 2min 34s, sys: 4.36 s, total: 2min 38s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crime_estimators, crime_scores = train_with_all_classifier(X_trn_crime, y_trn_crime,\n",
    "                                                                 'Communities and Crimes', X_tst_crime,y_tst_crime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f399f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(crime_scores, 'Communities and Crime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096858e",
   "metadata": {},
   "source": [
    "# ======================Dataset 3.  ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af8292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Preparing data for traing\n",
    "#getting the default dataset\n",
    "#aquaticToxicity\n",
    "#since the data does not have label, so using the data description we have to label the data \n",
    "aquaticToxicity = pd.read_csv('resources2/qsar_aquatic_toxicity.csv',sep=';',names=[\"TPSA(Tot)\",\"SAacc\",\"H-050\",\"MLOGP\",\"RDCHI\",\"GATS1p\",\"nN\",\"C-040\",\"LC50\"])\n",
    "\n",
    "\n",
    "X = aquaticToxicity.drop('LC50', axis='columns')\n",
    "aquaticToxicity['LC50'] = encoder.fit_transform(aquaticToxicity['LC50'])\n",
    "y = aquaticToxicity['LC50']\n",
    "X['TPSA(Tot)'] = encoder.fit_transform(X['TPSA(Tot)'])\n",
    "X['SAacc'] = encoder.fit_transform(X['SAacc'])\n",
    "X['H-050'] = encoder.fit_transform(X['H-050'])\n",
    "X['MLOGP'] = encoder.fit_transform(X['MLOGP'])\n",
    "X['RDCHI'] = encoder.fit_transform(X['RDCHI'])\n",
    "X['GATS1p'] = encoder.fit_transform(X['GATS1p'])\n",
    "X['nN'] = encoder.fit_transform(X['nN'])\n",
    "y_lis = []\n",
    "for ele in y:\n",
    "    if ele < 500:\n",
    "        y_lis.append(1)\n",
    "    else:\n",
    "        y_lis.append(0)\n",
    "y = np.array(y_lis)\n",
    "display(aquaticToxicity)\n",
    "print('X: after encoding')\n",
    "display(X)\n",
    "\n",
    "X_trn_QSAR,X_tst_QSAR,y_trn_QSAR,y_tst_QSAR = separateData(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac3a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "QSAR_estimators, QSAR_scores = train_with_all_classifier(X_trn_QSAR, y_trn_QSAR,\n",
    "                                                                 'QSAR', X_tst_QSAR,y_tst_QSAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f09046",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(QSAR_scores, 'QSAR aquatic toxicity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6222a84e",
   "metadata": {},
   "source": [
    "# ===================Dataset 4. Facebook======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074ca183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the raw data\n",
    "\n",
    "fbData = pd.read_csv('resources2/dataset_Facebook.csv',sep=';')\n",
    "\n",
    "#we can see some of the rows have invalid data entries\n",
    "\n",
    "#preprocessing the data\n",
    "fbData.replace(r'^\\s*$', np.nan, regex=True, inplace = True)\n",
    "fbData.replace('?', np.nan, inplace = True)\n",
    "#print(fbData.isnull().sum())\n",
    "\n",
    "# as we are perdicting the total Intractions so we will not consider them \n",
    "unusefullFeatures = ['comment','like','share']\n",
    "fbData = fbData.drop(columns= unusefullFeatures, axis=1)\n",
    "fbData[\"Type\"].value_counts()\n",
    "\n",
    "# since datatype of \"Type\" is not interger, but we can make it integer by making four cloumns for each type ; link, photo, status, video\n",
    "lb_style = LabelBinarizer()\n",
    "lb_results = lb_style.fit_transform(fbData[\"Type\"])\n",
    "encoded_df = pd.DataFrame(lb_results, columns=lb_style.classes_)\n",
    "fbData = pd.concat([fbData,encoded_df], axis=1) \n",
    "cols = list(fbData)\n",
    "cols.insert(1, cols.pop(cols.index('Link')))\n",
    "cols.insert(2, cols.pop(cols.index('Photo')))\n",
    "cols.insert(3, cols.pop(cols.index('Status')))\n",
    "cols.insert(4, cols.pop(cols.index('Video')))\n",
    "fbData = fbData.loc[:, cols]\n",
    "fbData = fbData.drop(columns=['Type'],axis=1)\n",
    "#putting common values into the missing ones\n",
    "fbData = fbData.apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "fbData.shape\n",
    "(500, 19)\n",
    "\n",
    "#Since almost every raw data has outliers so we need to remove them \n",
    "outlierThresholdValue = np.percentile(fbData['Total Interactions'],90)\n",
    "fbData = fbData[fbData['Total Interactions'] < outlierThresholdValue]\n",
    "fbData.shape\n",
    "\n",
    "#Spliting the processed data into training and test datasets\n",
    "#fbX_train, fbX_test, fby_train, fby_test = train_test_split(fbData.iloc[:, 0:18].values, fbData.iloc[:, 18].values, test_size=0.33, random_state=0)\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(fbX_train)\n",
    "#fbx_train_scaled = scaler.transform(fbX_train)\n",
    "#fbx_test_scaled = scaler.transform(fbX_test)\n",
    "fbData\n",
    "X = fbData.drop('Total Interactions', axis='columns')\n",
    "y = fbData['Total Interactions']\n",
    "\n",
    "X_trn_facebook, X_tst_facebook, y_trn_facebook, y_tst_facebook = separateData(X,y)\n",
    "\n",
    "fbData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba13eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "facebook_estimators, facebook_scores = train_with_all_classifier(X_trn_facebook, y_trn_facebook,\n",
    "                                                                 'Facebook metrics', X_tst_facebook,y_tst_facebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635f8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(facebook_scores, 'Facebook metrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766afa68",
   "metadata": {},
   "source": [
    "# =====================Dataset 5. Biking=======================\n",
    "- To minimize training time, we are cutting the data to only 5000 data rather than 17000+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ce60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikeHours = pd.read_csv('resources2/hour.csv')\n",
    "X = bikeHours.drop('cnt', axis='columns')\n",
    "y = bikeHours['cnt']\n",
    "\n",
    "print('Before encoding')\n",
    "display(bikeHours)\n",
    "\n",
    "X['dteday'] = encoder.fit_transform(X['dteday'])\n",
    "#X['temp'] = encoder.fit_transform(X['temp'])\n",
    "#X['atemp'] = encoder.fit_transform(X['atemp'])\n",
    "#X['windspeed'] = encoder.fit_transform(X['windspeed'])\n",
    "\n",
    "X_trn_biking, X_tst_biking, y_trn_biking, y_tst_biking = separateData(X,y)\n",
    "\n",
    "print('X: After encoding')\n",
    "display(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9215e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "biking_estimators, biking_scores = train_with_all_classifier(X_trn_biking, y_trn_biking,\n",
    "                                                                 'Facebook metrics', X_tst_biking,y_tst_biking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905db6d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc4c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ec81cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e532f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9df8a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7528b9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ed0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2729b67f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55af7d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(scores, 'Bike Sharing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542f42a2",
   "metadata": {},
   "source": [
    "# ====================Dataset 6. Students====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b78b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "studentPortMarks = pd.read_csv('resources2/student-por.csv',sep=';',  skipinitialspace=True)\n",
    "\n",
    "print('Before encoding')\n",
    "display(studentPortMarks)\n",
    "\n",
    "X = studentPortMarks.drop('G3', axis='columns')\n",
    "y = studentPortMarks['G3']\n",
    "\n",
    "X['school'] = encoder.fit_transform(X['school'])\n",
    "X['sex'] = encoder.fit_transform(X['sex'])\n",
    "X['address'] = encoder.fit_transform(X['address'])\n",
    "X['famsize'] = encoder.fit_transform(X['famsize'])\n",
    "X['Pstatus'] = encoder.fit_transform(X['Pstatus'])\n",
    "X['Mjob'] = encoder.fit_transform(X['Mjob'])\n",
    "X['Fjob'] = encoder.fit_transform(X['Fjob'])\n",
    "X['reason'] = encoder.fit_transform(X['reason'])\n",
    "X['guardian'] = encoder.fit_transform(X['guardian'])\n",
    "X['schoolsup'] = encoder.fit_transform(X['schoolsup'])\n",
    "X['schoolsup'] = encoder.fit_transform(X['schoolsup'])\n",
    "X['famsup'] = encoder.fit_transform(X['famsup'])\n",
    "X['paid'] = encoder.fit_transform(X['paid'])\n",
    "X['activities'] = encoder.fit_transform(X['activities'])\n",
    "X['nursery'] = encoder.fit_transform(X['nursery'])\n",
    "X['higher'] = encoder.fit_transform(X['higher'])\n",
    "X['internet'] = encoder.fit_transform(X['internet'])\n",
    "X['romantic'] = encoder.fit_transform(X['romantic'])\n",
    "\n",
    "\n",
    "print('X: After encoding')\n",
    "display(X)\n",
    "\n",
    "X_trn_students, X_tst_students, y_trn_students, y_tst_students = separateData(X,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ec07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "students_estimators, students_scores = train_with_all_classifier(X_trn_students, y_trn_students,\n",
    "                                                                 'Students', X_tst_students,y_tst_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(students_scores, 'Student Performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2918d4c9",
   "metadata": {},
   "source": [
    "# ===========Dateset 7. Concrete Compressive Strength===========\n",
    "\n",
    "- It is suggested to have a compressive strength for concrete below 50, so let us create estimators where output gives 1 when \n",
    "- the compressive strength for concrete is > 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "concreteData = pd.read_excel('resources2/Concrete_Data.xls')\n",
    "\n",
    "X = concreteData.drop('Concrete compressive strength(MPa, megapascals) ', axis='columns')\n",
    "y = concreteData['Concrete compressive strength(MPa, megapascals) ']\n",
    "\n",
    "# encoding float numbers\n",
    "X['Cement (component 1)(kg in a m^3 mixture)'] = encoder.fit_transform(X['Cement (component 1)(kg in a m^3 mixture)'])\n",
    "X['Blast Furnace Slag (component 2)(kg in a m^3 mixture)'] = encoder.fit_transform(X['Blast Furnace Slag (component 2)(kg in a m^3 mixture)'])\n",
    "X['Fly Ash (component 3)(kg in a m^3 mixture)'] = encoder.fit_transform(X['Fly Ash (component 3)(kg in a m^3 mixture)'])\n",
    "X['Water  (component 4)(kg in a m^3 mixture)'] = encoder.fit_transform(X['Water  (component 4)(kg in a m^3 mixture)'])\n",
    "X['Superplasticizer (component 5)(kg in a m^3 mixture)'] = encoder.fit_transform(X['Superplasticizer (component 5)(kg in a m^3 mixture)'])\n",
    "X['Coarse Aggregate  (component 6)(kg in a m^3 mixture)'] = encoder.fit_transform(X['Coarse Aggregate  (component 6)(kg in a m^3 mixture)'])\n",
    "X['Fine Aggregate (component 7)(kg in a m^3 mixture)'] = encoder.fit_transform(X['Fine Aggregate (component 7)(kg in a m^3 mixture)'])\n",
    "y = y.astype('uint8')\n",
    "X_trn_concrete, X_tst_concrete, y_trn_concrete, y_tst_concrete = separateData(X,y)\n",
    "print('Before encoding')\n",
    "display(concreteData)\n",
    "print('After encoding')\n",
    "display(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f103bd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "concrete_estimators, concrete_scores = train_with_all_classifier(X_trn_concrete, y_trn_concrete,\n",
    "                                                                 'Concrete Compressive Strength', X_tst_concrete, y_tst_concrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304caa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(concrete_scores, 'Concrete Compressive Strength')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b3cb26",
   "metadata": {},
   "source": [
    "# ===================Dateset 8. GPU =================== "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5321bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting data\n",
    "gpuData = pd.read_csv(\"resources2/sgemm_product.csv\")\n",
    "display(gpuData)\n",
    "#checking null values\n",
    "#print(gpuData.isnull().sum())\n",
    "#Preparing the the dataset\n",
    "X = gpuData[gpuData.columns[:-4]] \n",
    "y = (gpuData['Run1 (ms)']+gpuData['Run2 (ms)']+gpuData['Run3 (ms)']+gpuData['Run4 (ms)'])/4\n",
    "\n",
    "\n",
    "#splitting the data into training and testing datasets\n",
    "y = encoder.fit_transform(y)\n",
    "X = X.astype('uint8')\n",
    "y = y.astype('uint8')\n",
    "X_trn_GPU, X_tst_GPU, y_trn_GPU, y_tst_GPU = separateData(X,y)\n",
    "\n",
    "print('averaging the 4 different runs and use it as y- output data')\n",
    "# only using 10000 data from all the existing data to maximize running time\n",
    "X_trn_GPU = X_trn_GPU.iloc[0:10000,:]\n",
    "y_trn_GPU = y_trn_GPU[0:10000]\n",
    "X_tst_GPU = X_tst_GPU.iloc[0:2000,:]\n",
    "y_tst_GPU = y_tst_GPU[0:2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ccc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "GPU_estimators, GPU_scores = train_with_all_classifier(X_trn_GPU, y_trn_GPU,\n",
    "                                                                 'GPU', X_tst_GPU, y_tst_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd77a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(GPU_scores, 'SGEMM GPU kernel performance ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
