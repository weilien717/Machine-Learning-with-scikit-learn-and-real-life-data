{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a8679a8",
   "metadata": {},
   "source": [
    "Wei Lien Huang 40128391\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93c84c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import os                        # for os.path.exists\n",
    "import json                      # for loading metadata\n",
    "import urllib                    # for downloading remote files \n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.tree\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n",
    "import sklearn.preprocessing\n",
    "import sklearn.gaussian_process\n",
    "import sklearn.neural_network\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn.naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe2c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateData(X,y):\n",
    "    X_trn, X_tst, y_trn, y_tst = sklearn.model_selection.train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    return X_trn, X_tst, y_trn, y_tst\n",
    "\n",
    "def readArff(dir):\n",
    "    data = arff.loadarff(dir)\n",
    "    df = pd.DataFrame(data[0])\n",
    "    data_list = []\n",
    "    data = np.array(df)\n",
    "    X = data[:,0:-1]\n",
    "    y_ = data[:,-1:]\n",
    "    y_lis = []\n",
    "    for ele in y_:\n",
    "        ele = ele[0].decode('utf-8')\n",
    "        if ele == 'T' or ele == '1':\n",
    "            y_lis.append(1)\n",
    "        if ele == 'F' or ele == '0':\n",
    "            y_lis.append(0)\n",
    "    y = np.array(y_lis).ravel().astype('int')\n",
    "    return X,y\n",
    "\n",
    "def removeRowWithMissingData(X_trn, y_trn, row):\n",
    "    newArrayX = []\n",
    "    newArrayy = []\n",
    "    counter = 0\n",
    "    for x in X_trn:\n",
    "        if x[row] != '?':\n",
    "            newArrayX.append(x)\n",
    "            newArrayy.append(y_trn[counter])\n",
    "        counter+=1\n",
    "    return np.array(newArrayX), np.array(newArrayy)\n",
    "\n",
    "def replaceMissingValueData(X_tst, row):\n",
    "    newArrayX = []\n",
    "    sum = 0\n",
    "    counter = 0\n",
    "    for x in X_tst:\n",
    "        if x[row] != '?':\n",
    "            sum += int(x[row])\n",
    "            counter+=1\n",
    "    \n",
    "    #compute average for this column with missing index\n",
    "    missingInputVal = int(sum / counter)\n",
    "    #replace values\n",
    "    for x in X_tst:\n",
    "        if x[row] == '?':\n",
    "            x[row] = missingInputVal\n",
    "    return X_tst\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd342491",
   "metadata": {},
   "source": [
    "# Extract the following databases\n",
    "1) [Diabetic Retinopathy ](https://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set)\n",
    "\n",
    "2) [Default of credit card clients](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)\n",
    "\n",
    "3) [Breast Cancer Wisconsin](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))\n",
    "\n",
    "4) [Statlog (German credit data) (recommend german.doc for instructions and german-numeric for data.)](https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data))\n",
    "\n",
    "5) [Adult](https://archive.ics.uci.edu/ml/datasets/adult)\n",
    "\n",
    "6) [Yeast](https://archive.ics.uci.edu/ml/datasets/Yeast)\n",
    "\n",
    "7) [Thoracic Surgery Data](https://archive.ics.uci.edu/ml/datasets/Thoracic+Surgery+Data)\n",
    "\n",
    "8) [Seismic-Bumps](https://archive.ics.uci.edu/ml/datasets/seismic-bumps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3581cd04",
   "metadata": {},
   "source": [
    "# 1) Diabetic Retinopathy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e14873ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>49.895756</td>\n",
       "      <td>17.775994</td>\n",
       "      <td>5.270920</td>\n",
       "      <td>0.771761</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.486903</td>\n",
       "      <td>0.100025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>57.709936</td>\n",
       "      <td>23.799994</td>\n",
       "      <td>3.325423</td>\n",
       "      <td>0.234185</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.520908</td>\n",
       "      <td>0.144414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>55.831441</td>\n",
       "      <td>27.993933</td>\n",
       "      <td>12.687485</td>\n",
       "      <td>4.852282</td>\n",
       "      <td>1.393889</td>\n",
       "      <td>0.373252</td>\n",
       "      <td>0.041817</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.530904</td>\n",
       "      <td>0.128548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>40.467228</td>\n",
       "      <td>18.445954</td>\n",
       "      <td>9.118901</td>\n",
       "      <td>3.079428</td>\n",
       "      <td>0.840261</td>\n",
       "      <td>0.272434</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.483284</td>\n",
       "      <td>0.114790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18.026254</td>\n",
       "      <td>8.570709</td>\n",
       "      <td>0.410381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475935</td>\n",
       "      <td>0.123572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1     2     3     4     5     6     7          8          9  \\\n",
       "0  1.0  1.0  22.0  22.0  22.0  19.0  18.0  14.0  49.895756  17.775994   \n",
       "1  1.0  1.0  24.0  24.0  22.0  18.0  16.0  13.0  57.709936  23.799994   \n",
       "2  1.0  1.0  62.0  60.0  59.0  54.0  47.0  33.0  55.831441  27.993933   \n",
       "3  1.0  1.0  55.0  53.0  53.0  50.0  43.0  31.0  40.467228  18.445954   \n",
       "4  1.0  1.0  44.0  44.0  44.0  41.0  39.0  27.0  18.026254   8.570709   \n",
       "\n",
       "          10        11        12        13        14        15        16  \\\n",
       "0   5.270920  0.771761  0.018632  0.006864  0.003923  0.003923  0.486903   \n",
       "1   3.325423  0.234185  0.003903  0.003903  0.003903  0.003903  0.520908   \n",
       "2  12.687485  4.852282  1.393889  0.373252  0.041817  0.007744  0.530904   \n",
       "3   9.118901  3.079428  0.840261  0.272434  0.007653  0.001531  0.483284   \n",
       "4   0.410381  0.000000  0.000000  0.000000  0.000000  0.000000  0.475935   \n",
       "\n",
       "         17   18  Class  \n",
       "0  0.100025  1.0      0  \n",
       "1  0.144414  0.0      0  \n",
       "2  0.128548  0.0      1  \n",
       "3  0.114790  0.0      0  \n",
       "4  0.123572  0.0      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the Diabetic Retinopathy data that is downloaded \n",
    "data = arff.loadarff('resources/messidor_features.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df['Class'] = encoder.fit_transform(df['Class'])\n",
    "X = df.drop('Class', axis='columns')\n",
    "y = df['Class']\n",
    "X_trn_diabetic, X_tst_diabetic, y_trn_diabetic, y_tst_diabetic = separateData(X,y)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef1049c",
   "metadata": {},
   "source": [
    "# 2) Default of credit card clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abf38d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>LIMIT_BAL</td>\n",
       "      <td>SEX</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>MARRIAGE</td>\n",
       "      <td>AGE</td>\n",
       "      <td>PAY_0</td>\n",
       "      <td>PAY_2</td>\n",
       "      <td>PAY_3</td>\n",
       "      <td>PAY_4</td>\n",
       "      <td>...</td>\n",
       "      <td>BILL_AMT4</td>\n",
       "      <td>BILL_AMT5</td>\n",
       "      <td>BILL_AMT6</td>\n",
       "      <td>PAY_AMT1</td>\n",
       "      <td>PAY_AMT2</td>\n",
       "      <td>PAY_AMT3</td>\n",
       "      <td>PAY_AMT4</td>\n",
       "      <td>PAY_AMT5</td>\n",
       "      <td>PAY_AMT6</td>\n",
       "      <td>default payment next month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0         X1   X2         X3        X4   X5     X6     X7     X8  \\\n",
       "0         ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3   \n",
       "1          1      20000    2          2         1   24      2      2     -1   \n",
       "2          2     120000    2          2         2   26     -1      2      0   \n",
       "3          3      90000    2          2         2   34      0      0      0   \n",
       "4          4      50000    2          2         1   37      0      0      0   \n",
       "\n",
       "      X9  ...        X15        X16        X17       X18       X19       X20  \\\n",
       "0  PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3   \n",
       "1     -1  ...          0          0          0         0       689         0   \n",
       "2      0  ...       3272       3455       3261         0      1000      1000   \n",
       "3      0  ...      14331      14948      15549      1518      1500      1000   \n",
       "4      0  ...      28314      28959      29547      2000      2019      1200   \n",
       "\n",
       "        X21       X22       X23                           Y  \n",
       "0  PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "1         0         0         0                           1  \n",
       "2      1000         0      2000                           1  \n",
       "3      1000      1000      5000                           0  \n",
       "4      1100      1069      1000                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel (r'resources/default of credit card clients.xls')\n",
    "X = np.array(data)[1:,1:-1]\n",
    "y = np.array(data)[1:,-1:].ravel().astype('int')\n",
    "X_trn_credit, X_tst_credit, y_trn_credit, y_tst_credit = separateData(X,y)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1b1413",
   "metadata": {},
   "source": [
    "# 3) Breast Cancer Wisconsin \n",
    "\n",
    "- if y = 2 --> benign    we will change this value to 0\n",
    "\n",
    "- if y = 4 --> malignant we will change this value to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce9310be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>radius</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>concavity</th>\n",
       "      <th>concave points</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000025</th>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002945</th>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015425</th>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016277</th>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017023</th>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           radius  perimeter  area  smoothness  compactness  concavity   \\\n",
       "1000025 5       1          1     1            2           1           3   \n",
       "1002945 5       4          4     5            7          10           3   \n",
       "1015425 3       1          1     1            2           2           3   \n",
       "1016277 6       8          8     1            3           4           3   \n",
       "1017023 4       1          1     3            2           1           3   \n",
       "\n",
       "           concave points  symmetry  fractal dimension  \n",
       "1000025 5               1         1                  2  \n",
       "1002945 5               2         1                  2  \n",
       "1015425 3               1         1                  2  \n",
       "1016277 6               7         1                  2  \n",
       "1017023 4               1         1                  2  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('resources/breast-cancer-wisconsin.data', header=None, names=[\"radius\",\"perimeter\",\"area\",\"smoothness \",\n",
    "                                                                                 \"compactness\",\"concavity \",\"concave points\",\"symmetry\",\"fractal dimension\"])\n",
    "\n",
    "X = np.array(data)[:,0:-1]\n",
    "y = np.array(data)[:,-1:]\n",
    "y_lis = []\n",
    "for ele in y:\n",
    "    if ele == 2:\n",
    "        y_lis.append(0)\n",
    "    if ele == 4:\n",
    "        y_lis.append(1)\n",
    "y = np.array(y_lis).ravel().astype('int')\n",
    "\n",
    "X_trn_breast, X_tst_breast, y_trn_breast, y_tst_breast = separateData(X,y)\n",
    "# remove the row with missing value in the trainning set\n",
    "X_trn_breast,y_trn_breast = removeRowWithMissingData(X_trn_breast,y_trn_breast, 6)\n",
    "\n",
    "# filtering out the missing value and replace it by the average of all other existing values\n",
    "X_tst_breast = replaceMissingValueData(X_tst_breast, 6)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e22c3f",
   "metadata": {},
   "source": [
    "# 4) Statlog (German credit data) (recommend german.doc for instructions and german-numeric for data.)\n",
    "please refer on [uci dataset](https://archive.ics.uci.edu/ml/datasets/adult) to view the labels of each corresponding data row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb1835b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  15  16  17  18  19  20  21  \\\n",
       "0   1   6   4  12   5   5   3   4   1  67  ...   0   0   1   0   0   1   0   \n",
       "1   2  48   2  60   1   3   2   2   1  22  ...   0   0   1   0   0   1   0   \n",
       "2   4  12   4  21   1   4   3   3   1  49  ...   0   0   1   0   0   1   0   \n",
       "3   1  42   2  79   1   4   3   4   2  45  ...   0   0   0   0   0   0   0   \n",
       "4   1  24   3  49   1   3   3   4   4  53  ...   1   0   1   0   0   0   0   \n",
       "\n",
       "   22  23  24  \n",
       "0   0   1   1  \n",
       "1   0   1   2  \n",
       "2   1   0   1  \n",
       "3   0   1   1  \n",
       "4   0   1   2  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('resources/german.data-numeric', header=None,  delim_whitespace=True)\n",
    "X = np.array(data)[:,0:-1]\n",
    "y = np.array(data)[:,-1:].ravel().astype('int')\n",
    "X_trn_german, X_tst_german, y_trn_german, y_tst_german = separateData(X,y)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b329d8f",
   "metadata": {},
   "source": [
    "# 5) Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95fadd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income exceeds $50K/yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \\\n",
       "0          2174             0              40   United-States   \n",
       "1             0             0              13   United-States   \n",
       "2             0             0              40   United-States   \n",
       "3             0             0              40   United-States   \n",
       "4             0             0              40            Cuba   \n",
       "\n",
       "   income exceeds $50K/yr  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('resources/adult.data',  header=None, names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "                                                                'marital-status', 'occupation', 'relationship', 'race',\n",
    "                                                                'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "                                                                'income exceeds $50K/yr'])\n",
    "df['income exceeds $50K/yr'] = encoder.fit_transform(df['income exceeds $50K/yr'])\n",
    "X = df.drop('income exceeds $50K/yr', axis='columns')\n",
    "y = df['income exceeds $50K/yr']\n",
    "X['workclass'] = encoder.fit_transform(X['workclass'])\n",
    "X['education'] = encoder.fit_transform(X['education'])\n",
    "X['marital-status'] = encoder.fit_transform(X['marital-status'])\n",
    "X['occupation'] = encoder.fit_transform(X['occupation'])\n",
    "X['relationship'] = encoder.fit_transform(X['relationship'])\n",
    "X['race'] = encoder.fit_transform(X['race'])\n",
    "X['sex'] = encoder.fit_transform(X['sex'])\n",
    "X['native-country'] = encoder.fit_transform(X['native-country'])\n",
    "\n",
    "X_trn_adult, X_tst_adult, y_trn_adult, y_tst_adult = separateData(X,y)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a5464d",
   "metadata": {},
   "source": [
    "# 6) Yeast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4225f526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence Name</th>\n",
       "      <th>mcg</th>\n",
       "      <th>gvh</th>\n",
       "      <th>alm</th>\n",
       "      <th>mit</th>\n",
       "      <th>erl</th>\n",
       "      <th>pox</th>\n",
       "      <th>vac</th>\n",
       "      <th>nuc</th>\n",
       "      <th>Cellular Localization Sites of Proteins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADT1_YEAST</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADT2_YEAST</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADT3_YEAST</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAR2_YEAST</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.22</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AATM_YEAST</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence Name   mcg   gvh   alm   mit  erl  pox   vac   nuc  \\\n",
       "0    ADT1_YEAST  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22   \n",
       "1    ADT2_YEAST  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22   \n",
       "2    ADT3_YEAST  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22   \n",
       "3    AAR2_YEAST  0.58  0.44  0.57  0.13  0.5  0.0  0.54  0.22   \n",
       "4    AATM_YEAST  0.42  0.44  0.48  0.54  0.5  0.0  0.48  0.22   \n",
       "\n",
       "   Cellular Localization Sites of Proteins  \n",
       "0                                        6  \n",
       "1                                        6  \n",
       "2                                        6  \n",
       "3                                        7  \n",
       "4                                        6  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('resources/yeast.data', header=None, delim_whitespace=True, names = ['sequence Name','mcg','gvh','alm','mit',\n",
    "                                                                                      'erl','pox','vac','nuc',\n",
    "                                                                                      'Cellular Localization Sites of Proteins'\n",
    "                                                                                     ])\n",
    "df['Cellular Localization Sites of Proteins'] = encoder.fit_transform(df['Cellular Localization Sites of Proteins'])\n",
    "X = df.drop('Cellular Localization Sites of Proteins', axis='columns')\n",
    "y = df['Cellular Localization Sites of Proteins']\n",
    "\n",
    "X['sequence Name'] = encoder.fit_transform(X['sequence Name'])\n",
    "X_trn_yeast, X_tst_yeast, y_trn_yeast, y_tst_yeast = separateData(X,y)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887fb15b",
   "metadata": {},
   "source": [
    "# 7) Thoracic Surgery Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "452ab3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN</th>\n",
       "      <th>PRE4</th>\n",
       "      <th>PRE5</th>\n",
       "      <th>PRE6</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE14</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Risk1Yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DGN  PRE4  PRE5  PRE6  PRE7  PRE8  PRE9  PRE10  PRE11  PRE14  PRE17  PRE19  \\\n",
       "0    1  2.88  2.16     1     0     0     0      1      1      3      0      0   \n",
       "1    2  3.40  1.88     0     0     0     0      0      0      1      0      0   \n",
       "2    2  2.76  2.08     1     0     0     0      1      0      0      0      0   \n",
       "3    2  3.68  3.04     0     0     0     0      0      0      0      0      0   \n",
       "4    2  2.44  0.96     2     0     1     0      1      1      0      0      0   \n",
       "\n",
       "   PRE25  PRE30  PRE32  AGE  Risk1Yr  \n",
       "0      0      1      0   22        0  \n",
       "1      0      1      0   13        0  \n",
       "2      0      1      0   21        0  \n",
       "3      0      0      0   16        0  \n",
       "4      0      1      0   35        1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = arff.loadarff('resources/ThoraricSurgery.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "df['Risk1Yr'] = encoder.fit_transform(df['Risk1Yr'])\n",
    "df['AGE'] = encoder.fit_transform(df['AGE'])\n",
    "df['PRE32'] = encoder.fit_transform(df['PRE32'])\n",
    "df['PRE30'] = encoder.fit_transform(df['PRE30'])\n",
    "df['PRE25'] = encoder.fit_transform(df['PRE25'])\n",
    "df['PRE19'] = encoder.fit_transform(df['PRE19'])\n",
    "df['PRE17'] = encoder.fit_transform(df['PRE17'])\n",
    "df['PRE14'] = encoder.fit_transform(df['PRE14'])\n",
    "df['PRE11'] = encoder.fit_transform(df['PRE11'])\n",
    "df['PRE10'] = encoder.fit_transform(df['PRE10'])\n",
    "df['PRE9'] = encoder.fit_transform(df['PRE9'])\n",
    "df['PRE8'] = encoder.fit_transform(df['PRE8'])\n",
    "df['PRE7'] = encoder.fit_transform(df['PRE7'])\n",
    "df['PRE6'] = encoder.fit_transform(df['PRE6'])\n",
    "df['DGN'] = encoder.fit_transform(df['DGN'])\n",
    "\n",
    "X = df.drop('Risk1Yr', axis='columns')\n",
    "y = df['Risk1Yr']\n",
    "X_trn_thoracic, X_tst_thoracic, y_trn_thoracic, y_tst_thoracic = separateData(X,y)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee133bb",
   "metadata": {},
   "source": [
    "# 8) Seismic-Bumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cfbb326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seismic</th>\n",
       "      <th>seismoacoustic</th>\n",
       "      <th>shift</th>\n",
       "      <th>genergy</th>\n",
       "      <th>gpuls</th>\n",
       "      <th>gdenergy</th>\n",
       "      <th>gdpuls</th>\n",
       "      <th>ghazard</th>\n",
       "      <th>nbumps</th>\n",
       "      <th>nbumps2</th>\n",
       "      <th>nbumps3</th>\n",
       "      <th>nbumps4</th>\n",
       "      <th>nbumps5</th>\n",
       "      <th>nbumps6</th>\n",
       "      <th>nbumps7</th>\n",
       "      <th>nbumps89</th>\n",
       "      <th>energy</th>\n",
       "      <th>maxenergy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'a'</td>\n",
       "      <td>b'a'</td>\n",
       "      <td>b'N'</td>\n",
       "      <td>15180.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>b'a'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'a'</td>\n",
       "      <td>b'a'</td>\n",
       "      <td>b'N'</td>\n",
       "      <td>14720.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>b'a'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'a'</td>\n",
       "      <td>b'a'</td>\n",
       "      <td>b'N'</td>\n",
       "      <td>8050.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>b'a'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'a'</td>\n",
       "      <td>b'a'</td>\n",
       "      <td>b'N'</td>\n",
       "      <td>28820.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>b'a'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'a'</td>\n",
       "      <td>b'a'</td>\n",
       "      <td>b'N'</td>\n",
       "      <td>12640.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>b'a'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seismic seismoacoustic shift  genergy  gpuls  gdenergy  gdpuls ghazard  \\\n",
       "0    b'a'           b'a'  b'N'  15180.0   48.0     -72.0   -72.0    b'a'   \n",
       "1    b'a'           b'a'  b'N'  14720.0   33.0     -70.0   -79.0    b'a'   \n",
       "2    b'a'           b'a'  b'N'   8050.0   30.0     -81.0   -78.0    b'a'   \n",
       "3    b'a'           b'a'  b'N'  28820.0  171.0     -23.0    40.0    b'a'   \n",
       "4    b'a'           b'a'  b'N'  12640.0   57.0     -63.0   -52.0    b'a'   \n",
       "\n",
       "   nbumps  nbumps2  nbumps3  nbumps4  nbumps5  nbumps6  nbumps7  nbumps89  \\\n",
       "0     0.0      0.0      0.0      0.0      0.0      0.0      0.0       0.0   \n",
       "1     1.0      0.0      1.0      0.0      0.0      0.0      0.0       0.0   \n",
       "2     0.0      0.0      0.0      0.0      0.0      0.0      0.0       0.0   \n",
       "3     1.0      0.0      1.0      0.0      0.0      0.0      0.0       0.0   \n",
       "4     0.0      0.0      0.0      0.0      0.0      0.0      0.0       0.0   \n",
       "\n",
       "   energy  maxenergy  class  \n",
       "0     0.0        0.0      0  \n",
       "1  2000.0     2000.0      0  \n",
       "2     0.0        0.0      0  \n",
       "3  3000.0     3000.0      0  \n",
       "4     0.0        0.0      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X,y = readArff('resources/ThoraricSurgery.arff')\n",
    "data = arff.loadarff('resources/seismic-bumps.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df['class'] = encoder.fit_transform(df['class'])\n",
    "X = df.drop('class', axis='columns')\n",
    "y = df['class']\n",
    "X['seismic'] = encoder.fit_transform(X['seismic'])\n",
    "X['seismoacoustic'] = encoder.fit_transform(X['seismoacoustic'])\n",
    "X['shift'] = encoder.fit_transform(X['shift'])\n",
    "X['ghazard'] = encoder.fit_transform(X['ghazard'])\n",
    "X_trn_seismic, X_tst_seismic, y_trn_seismic, y_tst_seismic = separateData(X,y)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1cc760",
   "metadata": {},
   "source": [
    "# Now that all the 8 Classification datasets  have been extracted, we can now work on the trainning and plotting of each models\n",
    "\n",
    "\n",
    "- Linear regression\n",
    "- Support vector regression\n",
    "- Decision tree regression\n",
    "- Random forest regression\n",
    "- kk-nearest neighbours regression\n",
    "- AdaBoost regression\n",
    "- Gaussian process regression\n",
    "- Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b84504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using the Randomized Search\n",
    "def trainModel(model, param_distributions, X_trn, y_trn, data_name, **kwargs):\n",
    "    clf = model(**kwargs)\n",
    "    print('Trainning', clf.__class__.__name__ ,'classifier model with ' , data_name , 'data...')\n",
    "    \n",
    "    #use standard scaler to scale the data\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    X_trn = scaler.fit_transform(X_trn)\n",
    "    \n",
    "    search = sklearn.model_selection.RandomizedSearchCV(clf, param_distributions)\n",
    "    search.fit(X_trn, y_trn)\n",
    "    best_param = search.best_params_\n",
    "    print('using' , search.best_estimator_)\n",
    "    clf = model(**kwargs)\n",
    "    clf.set_params(**best_param)\n",
    "    clf.fit(X_trn, y_trn)\n",
    "    return clf\n",
    "\n",
    "# train the model using the Grid Search\n",
    "def trainModelGridSearch(model, param_distributions, X_trn, y_trn, data_name, **kwargs):\n",
    "    clf = model(**kwargs)\n",
    "    print('Trainning', clf.__class__.__name__ ,'classifier model with ' , data_name , 'data...')\n",
    "    \n",
    "    #use standard scaler to scale the data\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    X_trn = scaler.fit_transform(X_trn)\n",
    "    \n",
    "    search = sklearn.model_selection.GridSearchCV(clf, param_distributions)\n",
    "    search.fit(X_trn, y_trn)\n",
    "    best_param = search.best_params_\n",
    "    print('using' , search.best_estimator_)\n",
    "    clf = model(**kwargs)\n",
    "    clf.set_params(**best_param)\n",
    "    clf.fit(X_trn, y_trn)\n",
    "    return clf\n",
    "\n",
    "# compute the score of the input estimator\n",
    "def computeScore(estimator, X_test, y_test, data_name):\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    score = round(estimator.score(X_test, y_test), 2 )* 100\n",
    "    print('testing accuracy using ', estimator.__class__.__name__, 'for data', data_name , score, '%')\n",
    "    print()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9b9ed",
   "metadata": {},
   "source": [
    "# Create function to train this data using all different classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63f46e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all the classifiers with different \n",
    "def train_with_all_classifier(X_trn, y_trn, data_name, X_tst, y_tst):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    estimators = []\n",
    "    scores = []\n",
    "    \n",
    "    #Logistic Regression\n",
    "    param_distributions = {\n",
    "        'C' : [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "    }\n",
    "    logistic_estimator = trainModelGridSearch(sklearn.linear_model.LogisticRegression, param_distributions, X_trn, \n",
    "                                         y_trn, data_name, max_iter = 1000, random_state=0)\n",
    "    estimators.append(logistic_estimator)\n",
    "    scores.append(computeScore(logistic_estimator, X_tst, y_tst, data_name))\n",
    "    \n",
    "    #SVM\n",
    "    param_distributions = {\n",
    "        'C' : [0.01,0.1,1.0],\n",
    "        'gamma' : [0.1,0.5,2.0],\n",
    "    }\n",
    "    svm_estimator = trainModelGridSearch(sklearn.svm.SVC, param_distributions, X_trn, \n",
    "                                         y_trn, data_name, max_iter = 10, random_state=0)\n",
    "    estimators.append(svm_estimator)\n",
    "    scores.append(computeScore(svm_estimator, X_tst, y_tst, data_name))\n",
    "\n",
    "    \n",
    "    #Decision Tree Classifier\n",
    "    param_distributions = {\n",
    "            'criterion' : ['gini', 'entropy'],\n",
    "            'max_depth' : [2,4,6,10,20],\n",
    "    }\n",
    "    decision_tree_estimator = trainModel(sklearn.tree.DecisionTreeClassifier, param_distributions, X_trn, \n",
    "                                         y_trn, data_name, random_state=0)\n",
    "    estimators.append(decision_tree_estimator)\n",
    "    scores.append(computeScore(decision_tree_estimator, X_tst, y_tst, data_name))\n",
    "    \n",
    "    #Random Forest Classifier\n",
    "    param_distributions = {\n",
    "            'n_estimators' : [50,100,200,400],\n",
    "            'max_depth' : [2,4,6,10,20]\n",
    "    }\n",
    "    randomForest_estimator = trainModel(sklearn.ensemble.RandomForestClassifier, param_distributions, X_trn, \n",
    "                                         y_trn, data_name, random_state=0)\n",
    "    estimators.append(randomForest_estimator)\n",
    "    scores.append(computeScore(randomForest_estimator, X_tst, y_tst, data_name))\n",
    "    \n",
    "    #kneighbour classifier\n",
    "    param_distributions = {\n",
    "            'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            'n_neighbors' : [5,10,20]\n",
    "    }\n",
    "    kneighbours_estimator = trainModel(sklearn.neighbors.KNeighborsClassifier, param_distributions, X_trn, \n",
    "                                         y_trn, data_name)\n",
    "    estimators.append(kneighbours_estimator)\n",
    "    scores.append(computeScore(kneighbours_estimator, X_tst, y_tst, data_name))\n",
    "    \n",
    "    #Adaboost\n",
    "    param_distributions = {\n",
    "            'n_estimators' : [50,100,200,400],\n",
    "            'learning_rate' : [0.2,0.4,1.0,1.2,1.5,2.0]\n",
    "    }\n",
    "    Adaboost_estimator = trainModel(sklearn.ensemble.AdaBoostClassifier, param_distributions, X_trn, \n",
    "                                         y_trn, data_name, random_state=0)\n",
    "    estimators.append(Adaboost_estimator)\n",
    "    scores.append(computeScore(Adaboost_estimator, X_tst, y_tst, data_name))\n",
    "    \n",
    "    \n",
    "    #GaussianProcessRegressor\n",
    "    param_distributions = {\n",
    "            'var_smoothing' : [0.0000000001,0.000000001, 0.00000001,0.001,1],\n",
    "    }\n",
    "    Gaussian_estimator = trainModel(sklearn.naive_bayes.GaussianNB, param_distributions, X_trn, \n",
    "                                         y_trn, data_name)\n",
    "    estimators.append(Gaussian_estimator)\n",
    "    scores.append(computeScore(Gaussian_estimator, X_tst, y_tst, data_name))\n",
    "\n",
    "    \n",
    "    #neural_network MLPRegressor\n",
    "    param_distributions = {\n",
    "            'hidden_layer_sizes' : [10,100,1000,10000],\n",
    "            'learning_rate' : ['constant', 'invscaling', 'adaptive']\n",
    "    }\n",
    "    Neural_estimator = trainModel(sklearn.neural_network.MLPClassifier, param_distributions, X_trn, \n",
    "                                         y_trn, data_name, max_iter = 10, random_state=0)\n",
    "    estimators.append(Neural_estimator)\n",
    "    scores.append(computeScore(Neural_estimator, X_tst, y_tst, data_name))\n",
    "    print('---------------------------------------------------')\n",
    "    return estimators, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a20efc",
   "metadata": {},
   "source": [
    "# Diabetic Retinopathy\n",
    "\n",
    "- Let's apply the train_with_all_classifier function to train and compute the score... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2f8e945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning LogisticRegression classifier model with  Diabetic Retinopathy data...\n",
      "using LogisticRegression(C=100.0, max_iter=1000, random_state=0)\n",
      "testing accuracy using  LogisticRegression for data Diabetic Retinopathy 75.0 %\n",
      "\n",
      "Trainning SVC classifier model with  Diabetic Retinopathy data...\n",
      "using SVC(C=0.01, gamma=0.5, max_iter=10, random_state=0)\n",
      "testing accuracy using  SVC for data Diabetic Retinopathy 46.0 %\n",
      "\n",
      "Trainning DecisionTreeClassifier classifier model with  Diabetic Retinopathy data...\n",
      "using DecisionTreeClassifier(criterion='entropy', max_depth=6, random_state=0)\n",
      "testing accuracy using  DecisionTreeClassifier for data Diabetic Retinopathy 60.0 %\n",
      "\n",
      "Trainning RandomForestClassifier classifier model with  Diabetic Retinopathy data...\n",
      "using RandomForestClassifier(max_depth=6, n_estimators=50, random_state=0)\n",
      "testing accuracy using  RandomForestClassifier for data Diabetic Retinopathy 66.0 %\n",
      "\n",
      "Trainning KNeighborsClassifier classifier model with  Diabetic Retinopathy data...\n",
      "using KNeighborsClassifier(algorithm='brute', n_neighbors=20)\n",
      "testing accuracy using  KNeighborsClassifier for data Diabetic Retinopathy 64.0 %\n",
      "\n",
      "Trainning AdaBoostClassifier classifier model with  Diabetic Retinopathy data...\n",
      "using AdaBoostClassifier(learning_rate=1.2, n_estimators=100, random_state=0)\n",
      "testing accuracy using  AdaBoostClassifier for data Diabetic Retinopathy 69.0 %\n",
      "\n",
      "Trainning GaussianNB classifier model with  Diabetic Retinopathy data...\n",
      "using GaussianNB(var_smoothing=1e-08)\n",
      "testing accuracy using  GaussianNB for data Diabetic Retinopathy 45.0 %\n",
      "\n",
      "Trainning MLPClassifier classifier model with  Diabetic Retinopathy data...\n",
      "using MLPClassifier(hidden_layer_sizes=10000, learning_rate='adaptive', max_iter=10,\n",
      "              random_state=0)\n",
      "testing accuracy using  MLPClassifier for data Diabetic Retinopathy 68.0 %\n",
      "\n",
      "---------------------------------------------------\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "diabetic_estimators, diabetic_scores = train_with_all_classifier(X_trn_diabetic, y_trn_diabetic,\n",
    "                                                                 'Diabetic Retinopathy', X_tst_diabetic,y_tst_diabetic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c1e37f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning LogisticRegression classifier model with  Credit Card Transaction data...\n",
      "using LogisticRegression(max_iter=1000, random_state=0)\n",
      "testing accuracy using  LogisticRegression for data Credit Card Transaction 82.0 %\n",
      "\n",
      "Trainning SVC classifier model with  Credit Card Transaction data...\n",
      "using SVC(C=0.01, gamma=2.0, max_iter=10, random_state=0)\n",
      "testing accuracy using  SVC for data Credit Card Transaction 78.0 %\n",
      "\n",
      "Trainning DecisionTreeClassifier classifier model with  Credit Card Transaction data...\n",
      "using DecisionTreeClassifier(max_depth=4, random_state=0)\n",
      "testing accuracy using  DecisionTreeClassifier for data Credit Card Transaction 83.0 %\n",
      "\n",
      "Trainning RandomForestClassifier classifier model with  Credit Card Transaction data...\n",
      "using RandomForestClassifier(max_depth=10, n_estimators=400, random_state=0)\n",
      "testing accuracy using  RandomForestClassifier for data Credit Card Transaction 82.0 %\n",
      "\n",
      "Trainning KNeighborsClassifier classifier model with  Credit Card Transaction data...\n",
      "using KNeighborsClassifier(algorithm='ball_tree', n_neighbors=20)\n",
      "testing accuracy using  KNeighborsClassifier for data Credit Card Transaction 81.0 %\n",
      "\n",
      "Trainning AdaBoostClassifier classifier model with  Credit Card Transaction data...\n",
      "using AdaBoostClassifier(learning_rate=0.2, n_estimators=200, random_state=0)\n",
      "testing accuracy using  AdaBoostClassifier for data Credit Card Transaction 82.0 %\n",
      "\n",
      "Trainning GaussianNB classifier model with  Credit Card Transaction data...\n",
      "using GaussianNB(var_smoothing=1)\n",
      "testing accuracy using  GaussianNB for data Credit Card Transaction 80.0 %\n",
      "\n",
      "Trainning MLPClassifier classifier model with  Credit Card Transaction data...\n",
      "using MLPClassifier(hidden_layer_sizes=10000, learning_rate='invscaling', max_iter=10,\n",
      "              random_state=0)\n",
      "testing accuracy using  MLPClassifier for data Credit Card Transaction 82.0 %\n",
      "\n",
      "---------------------------------------------------\n",
      "Wall time: 27min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "credit_estimators, credit_scores = train_with_all_classifier(X_trn_credit, y_trn_credit,\n",
    "                                                             'Credit Card Transaction', X_tst_credit,y_tst_credit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6b0afe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning LogisticRegression classifier model with  Breast Cancer data...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '?'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-e671bb78be92>\u001b[0m in \u001b[0;36mtrain_with_all_classifier\u001b[1;34m(X_trn, y_trn, data_name, X_tst, y_tst)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;34m'C'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     }\n\u001b[1;32m---> 12\u001b[1;33m     logistic_estimator = trainModelGridSearch(sklearn.linear_model.LogisticRegression, param_distributions, X_trn, \n\u001b[0m\u001b[0;32m     13\u001b[0m                                          y_trn, data_name, max_iter = 1000, random_state=0)\n\u001b[0;32m     14\u001b[0m     \u001b[0mestimators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogistic_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-920b7917b84a>\u001b[0m in \u001b[0;36mtrainModelGridSearch\u001b[1;34m(model, param_distributions, X_trn, y_trn, data_name, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m#use standard scaler to scale the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mX_trn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_trn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0msearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    764\u001b[0m         \"\"\"\n\u001b[0;32m    765\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n_samples_seen_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m         X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n\u001b[0m\u001b[0;32m    767\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m                                 force_all_finite='allow-nan', reset=first_call)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '?'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "breast_estimators, breast_scores = train_with_all_classifier(X_trn_breast, y_trn_breast,\n",
    "                                                             'Breast Cancer', X_tst_breast,y_tst_breast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3b6d36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning LogisticRegression classifier model with  German credit data...\n",
      "using LogisticRegression(C=0.1, max_iter=1000, random_state=0)\n",
      "testing accuracy using  LogisticRegression for data German credit 78.0 %\n",
      "\n",
      "Trainning SVC classifier model with  German credit data...\n",
      "using SVC(C=0.01, gamma=2.0, max_iter=10, random_state=0)\n",
      "testing accuracy using  SVC for data German credit 71.0 %\n",
      "\n",
      "Trainning DecisionTreeClassifier classifier model with  German credit data...\n",
      "using DecisionTreeClassifier(max_depth=4, random_state=0)\n",
      "testing accuracy using  DecisionTreeClassifier for data German credit 73.0 %\n",
      "\n",
      "Trainning RandomForestClassifier classifier model with  German credit data...\n",
      "using RandomForestClassifier(max_depth=20, n_estimators=200, random_state=0)\n",
      "testing accuracy using  RandomForestClassifier for data German credit 77.0 %\n",
      "\n",
      "Trainning KNeighborsClassifier classifier model with  German credit data...\n",
      "using KNeighborsClassifier(algorithm='kd_tree', n_neighbors=20)\n",
      "testing accuracy using  KNeighborsClassifier for data German credit 73.0 %\n",
      "\n",
      "Trainning AdaBoostClassifier classifier model with  German credit data...\n",
      "using AdaBoostClassifier(random_state=0)\n",
      "testing accuracy using  AdaBoostClassifier for data German credit 78.0 %\n",
      "\n",
      "Trainning GaussianNB classifier model with  German credit data...\n",
      "using GaussianNB(var_smoothing=1e-10)\n",
      "testing accuracy using  GaussianNB for data German credit 70.0 %\n",
      "\n",
      "Trainning MLPClassifier classifier model with  German credit data...\n",
      "using MLPClassifier(hidden_layer_sizes=1000, learning_rate='adaptive', max_iter=10,\n",
      "              random_state=0)\n",
      "testing accuracy using  MLPClassifier for data German credit 78.0 %\n",
      "\n",
      "---------------------------------------------------\n",
      "Wall time: 50.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "german_estimators, german_scores = train_with_all_classifier(X_trn_german, y_trn_german,\n",
    "                                                             'German credit',X_tst_german,y_tst_german)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a6625012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning LogisticRegression classifier model with  Yeast data...\n",
      "using LogisticRegression(max_iter=1000, random_state=0)\n",
      "testing accuracy using  LogisticRegression for data Yeast 60.0 %\n",
      "\n",
      "Trainning SVC classifier model with  Yeast data...\n",
      "using SVC(C=0.1, gamma=0.1, max_iter=10, random_state=0)\n",
      "testing accuracy using  SVC for data Yeast 36.0 %\n",
      "\n",
      "Trainning DecisionTreeClassifier classifier model with  Yeast data...\n",
      "using DecisionTreeClassifier(max_depth=6, random_state=0)\n",
      "testing accuracy using  DecisionTreeClassifier for data Yeast 60.0 %\n",
      "\n",
      "Trainning RandomForestClassifier classifier model with  Yeast data...\n",
      "using RandomForestClassifier(max_depth=20, random_state=0)\n",
      "testing accuracy using  RandomForestClassifier for data Yeast 61.0 %\n",
      "\n",
      "Trainning KNeighborsClassifier classifier model with  Yeast data...\n",
      "using KNeighborsClassifier(algorithm='ball_tree', n_neighbors=10)\n",
      "testing accuracy using  KNeighborsClassifier for data Yeast 56.00000000000001 %\n",
      "\n",
      "Trainning AdaBoostClassifier classifier model with  Yeast data...\n",
      "using AdaBoostClassifier(learning_rate=1.5, n_estimators=400, random_state=0)\n",
      "testing accuracy using  AdaBoostClassifier for data Yeast 42.0 %\n",
      "\n",
      "Trainning GaussianNB classifier model with  Yeast data...\n",
      "using GaussianNB(var_smoothing=1)\n",
      "testing accuracy using  GaussianNB for data Yeast 59.0 %\n",
      "\n",
      "Trainning MLPClassifier classifier model with  Yeast data...\n",
      "using MLPClassifier(hidden_layer_sizes=10000, learning_rate='invscaling', max_iter=10,\n",
      "              random_state=0)\n",
      "testing accuracy using  MLPClassifier for data Yeast 60.0 %\n",
      "\n",
      "---------------------------------------------------\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "yeast_estimators, yeast_scores = train_with_all_classifier(X_trn_yeast, y_trn_yeast,\n",
    "                                                             'Yeast',X_tst_yeast,y_tst_yeast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ae686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning LogisticRegression classifier model with  Adult data...\n",
      "using LogisticRegression(C=10.0, max_iter=1000, random_state=0)\n",
      "testing accuracy using  LogisticRegression for data Adult 83.0 %\n",
      "\n",
      "Trainning SVC classifier model with  Adult data...\n",
      "using SVC(gamma=2.0, max_iter=10, random_state=0)\n",
      "testing accuracy using  SVC for data Adult 76.0 %\n",
      "\n",
      "Trainning DecisionTreeClassifier classifier model with  Adult data...\n",
      "using DecisionTreeClassifier(criterion='entropy', max_depth=6, random_state=0)\n",
      "testing accuracy using  DecisionTreeClassifier for data Adult 84.0 %\n",
      "\n",
      "Trainning RandomForestClassifier classifier model with  Adult data...\n",
      "using RandomForestClassifier(max_depth=20, n_estimators=400, random_state=0)\n",
      "testing accuracy using  RandomForestClassifier for data Adult 86.0 %\n",
      "\n",
      "Trainning KNeighborsClassifier classifier model with  Adult data...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "adult_estimators, adult_scores = train_with_all_classifier(X_trn_adult, y_trn_adult,\n",
    "                                                             'Adult',X_tst_adult,y_tst_adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a18434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "thoracic_estimators, thoracic_scores = train_with_all_classifier(X_trn_thoracic, y_trn_thoracic,\n",
    "                                                             'Thoracic Surgery',X_tst_thoracic, y_tst_thoracic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seismic_estimators, seismic_scores = train_with_all_classifier(X_trn_seismic, y_trn_seismic,\n",
    "                                                             'Seismic Bumps',X_tst_seismic,y_tst_seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb3e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_list = ['LogisticRegression', 'SVC', 'DecisionTreeClassifier','RandomForestClassifier','KNeighborsRegressor',\n",
    "                   'AdaBoostClassifier', 'GaussianNB','MLPRegressor ']\n",
    "#print(diabetic_estimators)\n",
    "\n",
    "for i in range(len(classifier_list)):\n",
    "    print(classifier_list[i], ': score ', diabetic_scores[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f353cf",
   "metadata": {},
   "source": [
    "# Function to plot the bar chart to compare the accuracy of each trained estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd78469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBarGraph(score_list, title):\n",
    "    # x-coordinates of left sides of bars\n",
    "    left = []\n",
    "    scores = []\n",
    "    # labels for bars\n",
    "    #tick_label = classifier_list\n",
    "    tick_label = []\n",
    "    plt.figure(figsize=(18,5))\n",
    "    plt.grid(zorder=0)\n",
    "    \n",
    "    plt.title(title)\n",
    "    for i in range(len(score_list)):\n",
    "        if score_list[i] > -40:\n",
    "            left.append(i+1)\n",
    "            scores.append(score_list[i])\n",
    "            tick_label.append(classifier_list[i])\n",
    "    plt.bar(left, scores, tick_label = tick_label,\n",
    "            width = 0.2, color = ['red', 'green'])\n",
    "   # print(scores)\n",
    "    best_score = max(scores)\n",
    "    plt.text(6, 60, 'best accuracy estimator = ' + classifier_list[score_list.index(best_score)] + ' score: '+ str(best_score) + ' %' , fontsize=15, color = 'brown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f7acb",
   "metadata": {},
   "source": [
    "# 1) Diabetic Retinopathy bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e476414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(diabetic_scores, 'Diabetic Retinopathy bar chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad706bc",
   "metadata": {},
   "source": [
    "# 2) Default of credit card clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae394d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(credit_scores, 'Default of credit card clients bar chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be4ba1",
   "metadata": {},
   "source": [
    "# 3) Breast Cancer Wisconsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381faf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(breast_scores, 'Breast Cancer Wisconsin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47be868",
   "metadata": {},
   "source": [
    "# 4) Statlog (German credit data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(german_scores, 'Statlog (German credit data)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e5a162",
   "metadata": {},
   "source": [
    "# 5) Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(adult_scores, 'Adult')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0591217",
   "metadata": {},
   "source": [
    "# 6) Yeast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea9bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(yeast_scores, 'Yeast')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc37720",
   "metadata": {},
   "source": [
    "# 7) Thoracic Surgery Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea000f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(thoracic_scores, 'Thoracic Surgery Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b027d57",
   "metadata": {},
   "source": [
    "# 8) Seismic-Bumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3851c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(seismic_scores, 'Seismic-Bumps')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
